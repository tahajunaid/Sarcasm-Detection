{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "## requirements:\n",
    "- tensorflow (latest)\n",
    "- nltk\n",
    "- sklearn\n",
    "- numpy \n",
    "- pandas\n",
    "- seaborn\n",
    "- matplotlib"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "4aBcbrxf3Ecg",
    "outputId": "75b8817a-f670-4d2b-b984-f3d33105dd7e"
   },
   "source": [
    "!pip install -q -U tensorflow-text\n",
    "!pip install -q tf-models-official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "ax1-liCL3BF8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "gradient": {
     "editing": false
    },
    "id": "SM3oh0Zc3BGA",
    "outputId": "d1542c6a-bf97-43ce-f880-07f1355b82aa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>If that's true, then Freedom of Speech is doom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Neener neener - is it time to go in from the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Just like the plastic gun fear, the armour pie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>So geology is a religion because we weren't he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Well done Monty. Mark that up as your first ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6515</th>\n",
       "      <td>1</td>\n",
       "      <td>depends on when the baby bird died.   run alon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6516</th>\n",
       "      <td>1</td>\n",
       "      <td>ok, sheesh, to clarify, women who arent aborti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6517</th>\n",
       "      <td>1</td>\n",
       "      <td>so..   eh??   hows this sound?   will it fly w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6518</th>\n",
       "      <td>1</td>\n",
       "      <td>I think we should put to a vote, the right of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6519</th>\n",
       "      <td>1</td>\n",
       "      <td>You have a blob of tissue in your \"but(sic)\"? ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6520 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class                                               text\n",
       "0         0  If that's true, then Freedom of Speech is doom...\n",
       "1         0  Neener neener - is it time to go in from the p...\n",
       "2         0  Just like the plastic gun fear, the armour pie...\n",
       "3         0  So geology is a religion because we weren't he...\n",
       "4         0  Well done Monty. Mark that up as your first ev...\n",
       "...     ...                                                ...\n",
       "6515      1  depends on when the baby bird died.   run alon...\n",
       "6516      1  ok, sheesh, to clarify, women who arent aborti...\n",
       "6517      1  so..   eh??   hows this sound?   will it fly w...\n",
       "6518      1  I think we should put to a vote, the right of ...\n",
       "6519      1  You have a blob of tissue in your \"but(sic)\"? ...\n",
       "\n",
       "[6520 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_data=pd.read_csv(\"GEN-sarc-notsarc.csv\")\n",
    "data=main_data.copy()\n",
    "data.drop(columns=['id'],axis=1,inplace=True)\n",
    "classes = {\"notsarc\" : 0,\"sarc\" : 1}\n",
    "data[\"class\"] = data[\"class\"].map(classes)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "_38Q5FNw3BGD"
   },
   "outputs": [],
   "source": [
    "X=data['text']\n",
    "y=data['class']\n",
    "X=np.array(X)\n",
    "y=np.asarray(y).astype('int32')#.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "lpmfwitx3BGE"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data len:5216\n",
      "Class distribution\n",
      "1    2616\n",
      "0    2600\n",
      "dtype: int64\n",
      "Test data len:1304\n",
      "Class distribution\n",
      "0    660\n",
      "1    644\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Train data len:'+str(len(X_train)))\n",
    "print('Class distribution\\n'+str((pd.Series(y_train)).value_counts()))\n",
    "print('Test data len:'+str(len(X_test)))\n",
    "print('Class distribution\\n'+str((pd.Series(y_test)).value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data len:4172\n",
      "Class distribution\n",
      "0    2087\n",
      "1    2085\n",
      "dtype: int64\n",
      "Valid data len:1044\n",
      "Class distribution\n",
      "1    531\n",
      "0    513\n",
      "dtype: int64\n",
      "Test data len:1304\n",
      "Class distribution\n",
      "0    660\n",
      "1    644\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Train data len:'+str(len(X_train)))\n",
    "print('Class distribution\\n'+str((pd.Series(y_train)).value_counts()))\n",
    "print('Valid data len:'+str(len(X_valid)))\n",
    "print('Class distribution\\n'+str((pd.Series(y_valid)).value_counts()))\n",
    "print('Test data len:'+str(len(X_test)))\n",
    "print('Class distribution\\n'+str((pd.Series(y_test)).value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gradient": {},
    "id": "EDvx7R7V3BGE"
   },
   "outputs": [],
   "source": [
    "tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1'\n",
    "tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gradient": {},
    "id": "oasTqHRC3BGF"
   },
   "outputs": [],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "gradient": {},
    "id": "RfPdRUSm3BGH"
   },
   "outputs": [],
   "source": [
    "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "gradient": {},
    "id": "-YnPoQA33BGJ"
   },
   "outputs": [],
   "source": [
    "def build_classifier_model():\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    net = outputs['pooled_output']\n",
    "    net = tf.keras.layers.Dropout(0.1)(net)\n",
    "    net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n",
    "    return tf.keras.Model(text_input, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "gradient": {},
    "id": "gzCcgBG03BGJ"
   },
   "outputs": [],
   "source": [
    "classifier_model = build_classifier_model()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {},
    "id": "AwLW1NTN3BGK",
    "outputId": "28bc9c6e-21d2-485c-fc37-83ef6a509676"
   },
   "source": [
    "bert_raw_result = classifier_model(tf.constant(text_test))\n",
    "print(tf.sigmoid(bert_raw_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "gradient": {},
    "id": "jIBBkiV23BGL"
   },
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "metrics = tf.metrics.BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "gradient": {},
    "id": "Ys_RlKzz3BGL"
   },
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(32)\n",
    "valid_ds = tf.data.Dataset.from_tensor_slices((X_valid, y_valid)).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "IlKkCSm23BGM",
    "outputId": "184ce181-c7c8-4ab5-8b2a-da4b767fe96d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None,), (None,)), types: (tf.string, tf.int32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "ckUlBFJp3BGM"
   },
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "init_lr = 3e-5\n",
    "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                          num_train_steps=num_train_steps,\n",
    "                                          num_warmup_steps=num_warmup_steps,\n",
    "                                          optimizer_type='adamw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "qmrckhQb3BGM"
   },
   "outputs": [],
   "source": [
    "classifier_model.compile(optimizer=optimizer,\n",
    "                         loss=loss,\n",
    "                         metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "n3qKobso3BGM",
    "outputId": "3c1f0c8e-168c-451d-a468-ee8cc605f26a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1\n",
      "Epoch 1/3\n",
      "131/131 [==============================] - 2015s 15s/step - loss: 0.5496 - binary_accuracy: 0.6997 - val_loss: 0.4862 - val_binary_accuracy: 0.7739\n",
      "Epoch 2/3\n",
      "131/131 [==============================] - 2000s 15s/step - loss: 0.3829 - binary_accuracy: 0.8224 - val_loss: 0.5327 - val_binary_accuracy: 0.7586\n",
      "Epoch 3/3\n",
      "131/131 [==============================] - 1993s 15s/step - loss: 0.2413 - binary_accuracy: 0.9084 - val_loss: 0.6217 - val_binary_accuracy: 0.7615\n"
     ]
    }
   ],
   "source": [
    "print(f'Training model with {tfhub_handle_encoder}')\n",
    "history = classifier_model.fit(x=train_ds,\n",
    "                               validation_data=valid_ds,\n",
    "                               epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81       660\n",
      "           1       0.81      0.79      0.80       644\n",
      "\n",
      "    accuracy                           0.80      1304\n",
      "   macro avg       0.80      0.80      0.80      1304\n",
      "weighted avg       0.80      0.80      0.80      1304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred=classifier_model.predict(X_test)\n",
    "labels = [0, 1]\n",
    "print(classification_report(y_test,tf.round(tf.nn.sigmoid(y_pred)),labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "gradient": {
     "editing": false
    },
    "id": "BYeZrbCt3BGN",
    "outputId": "7d3cac5a-5d00-43a9-9039-ce55abe26da9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 179s 4s/step - loss: 0.5008 - binary_accuracy: 0.7952\n",
      "Loss: 0.5007590651512146\n",
      "Accuracy: 0.7952454090118408\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = classifier_model.evaluate(test_ds)\n",
    "\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 970). These functions will not be directly callable after loading.\n"
     ]
    }
   ],
   "source": [
    "model_name='BERT_TalkingHeads_Sarcasm_GEN_'+str(accuracy)\n",
    "classifier_model.save(model_name, include_optimizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "T6u4oCva3BGN"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>have no predators to fear? check. who said we ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2 hours? damn!  that book took me a good 2 day...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>you never played myst? damn!!! i must be reall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Well, if Genesis was in fact true, then we wou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Just making sure that everybody is aware of hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159</th>\n",
       "      <td>1</td>\n",
       "      <td>you really believed me? wow! i never knew i ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160</th>\n",
       "      <td>1</td>\n",
       "      <td>please tell me you're kidding. these bowling b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1161</th>\n",
       "      <td>1</td>\n",
       "      <td>you're kidding. just because your life is 'a f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1162</th>\n",
       "      <td>1</td>\n",
       "      <td>the evidence that is provided to you is not en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>1</td>\n",
       "      <td>you're kidding, right? i mean, you really don'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1164 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class                                               text\n",
       "0         0  have no predators to fear? check. who said we ...\n",
       "1         0  2 hours? damn!  that book took me a good 2 day...\n",
       "2         0  you never played myst? damn!!! i must be reall...\n",
       "3         0  Well, if Genesis was in fact true, then we wou...\n",
       "4         0  Just making sure that everybody is aware of hi...\n",
       "...     ...                                                ...\n",
       "1159      1  you really believed me? wow! i never knew i ha...\n",
       "1160      1  please tell me you're kidding. these bowling b...\n",
       "1161      1  you're kidding. just because your life is 'a f...\n",
       "1162      1  the evidence that is provided to you is not en...\n",
       "1163      1  you're kidding, right? i mean, you really don'...\n",
       "\n",
       "[1164 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv(\"HYP-sarc-notsarc.csv\")\n",
    "test_data.drop(columns=['id'],axis=1,inplace=True)\n",
    "classes = {\"notsarc\" : 0,\"sarc\" : 1}\n",
    "test_data[\"class\"] = test_data[\"class\"].map(classes)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "cRJxs3BM3BGO"
   },
   "outputs": [],
   "source": [
    "test_X=test_data['text']\n",
    "test_y=test_data['class']\n",
    "test_X=np.array(test_X)\n",
    "test_y=np.asarray(test_y).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "gradient": {},
    "id": "1_9h-opy3BGO"
   },
   "outputs": [],
   "source": [
    "test_tf = tf.data.Dataset.from_tensor_slices((test_X, test_y)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.48      0.58       582\n",
      "           1       0.62      0.85      0.71       582\n",
      "\n",
      "    accuracy                           0.66      1164\n",
      "   macro avg       0.69      0.66      0.65      1164\n",
      "weighted avg       0.69      0.66      0.65      1164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_y=classifier_model.predict(test_X)\n",
    "print(classification_report(test_y,tf.round(tf.nn.sigmoid(pred_y)),labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "gradient": {},
    "id": "xVFsVHYA3BGO",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 160s 4s/step - loss: 0.8586 - binary_accuracy: 0.6761\n",
      "Loss: 0.8586003184318542\n",
      "Accuracy: 0.6761168241500854\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = classifier_model.evaluate(test_tf)\n",
    "\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "gradient": {},
    "id": "JazexIoe3BGO"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Archie, the ONLY issue that gays don't have a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>No, not really. All that is different is the n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>It's ashame that everyone keeps looking for th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Almost? Usually, that is true, and it involves...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>And so have animals. Plants have been wiped ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>1</td>\n",
       "      <td>Tell me genius, how is me accurately and corre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>1</td>\n",
       "      <td>So you think it is a good idea for public scho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>1</td>\n",
       "      <td>Now settle down charlie, and try to think rati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>1</td>\n",
       "      <td>The VPC has a political agenda. The FBI? That ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>1</td>\n",
       "      <td>And I didn't. Did you note how I explicitly pu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1702 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class                                               text\n",
       "0         0  Archie, the ONLY issue that gays don't have a ...\n",
       "1         0  No, not really. All that is different is the n...\n",
       "2         0  It's ashame that everyone keeps looking for th...\n",
       "3         0  Almost? Usually, that is true, and it involves...\n",
       "4         0  And so have animals. Plants have been wiped ou...\n",
       "...     ...                                                ...\n",
       "1697      1  Tell me genius, how is me accurately and corre...\n",
       "1698      1  So you think it is a good idea for public scho...\n",
       "1699      1  Now settle down charlie, and try to think rati...\n",
       "1700      1  The VPC has a political agenda. The FBI? That ...\n",
       "1701      1  And I didn't. Did you note how I explicitly pu...\n",
       "\n",
       "[1702 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data2=pd.read_csv(\"RQ-sarc-notsarc.csv\")\n",
    "test_data2.drop(columns=['id'],axis=1,inplace=True)\n",
    "classes = {\"notsarc\" : 0,\"sarc\" : 1}\n",
    "test_data2[\"class\"] = test_data2[\"class\"].map(classes)\n",
    "test_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "gradient": {},
    "id": "K3AbPnzg3BGO"
   },
   "outputs": [],
   "source": [
    "test2_X=test_data2['text']\n",
    "test2_y=test_data2['class']\n",
    "test2_X=np.array(test2_X)\n",
    "test2_y=np.asarray(test2_y).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.80       851\n",
      "           1       0.79      0.81      0.80       851\n",
      "\n",
      "    accuracy                           0.80      1702\n",
      "   macro avg       0.80      0.80      0.80      1702\n",
      "weighted avg       0.80      0.80      0.80      1702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_y2=classifier_model.predict(test2_X)\n",
    "print(classification_report(test2_y,tf.round(tf.nn.sigmoid(pred_y2)),labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "gradient": {},
    "id": "2UzlDTWT3BGP",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 238s 4s/step - loss: 0.5319 - binary_accuracy: 0.7967\n",
      "Loss: 0.5319376587867737\n",
      "Accuracy: 0.7967097759246826\n"
     ]
    }
   ],
   "source": [
    "test2_tf = tf.data.Dataset.from_tensor_slices((test2_X,test2_y)).batch(32)\n",
    "loss, accuracy = classifier_model.evaluate(test2_tf)\n",
    "\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "pOFP73nb3BGP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "BERT - talking heads - Sarcasm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
