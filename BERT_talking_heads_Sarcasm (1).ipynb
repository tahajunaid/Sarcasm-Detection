{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "## requirements:\n",
    "- tensorflow (latest)\n",
    "- nltk\n",
    "- sklearn\n",
    "- numpy \n",
    "- pandas\n",
    "- seaborn\n",
    "- matplotlib"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "4aBcbrxf3Ecg",
    "outputId": "75b8817a-f670-4d2b-b984-f3d33105dd7e"
   },
   "source": [
    "!pip install -q -U tensorflow-text\n",
    "!pip install -q tf-models-official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "ax1-liCL3BF8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "gradient": {
     "editing": false
    },
    "id": "SM3oh0Zc3BGA",
    "outputId": "d1542c6a-bf97-43ce-f880-07f1355b82aa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>If that's true, then Freedom of Speech is doom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Neener neener - is it time to go in from the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Just like the plastic gun fear, the armour pie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>So geology is a religion because we weren't he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Well done Monty. Mark that up as your first ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6515</th>\n",
       "      <td>1</td>\n",
       "      <td>depends on when the baby bird died.   run alon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6516</th>\n",
       "      <td>1</td>\n",
       "      <td>ok, sheesh, to clarify, women who arent aborti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6517</th>\n",
       "      <td>1</td>\n",
       "      <td>so..   eh??   hows this sound?   will it fly w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6518</th>\n",
       "      <td>1</td>\n",
       "      <td>I think we should put to a vote, the right of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6519</th>\n",
       "      <td>1</td>\n",
       "      <td>You have a blob of tissue in your \"but(sic)\"? ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6520 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class                                               text\n",
       "0         0  If that's true, then Freedom of Speech is doom...\n",
       "1         0  Neener neener - is it time to go in from the p...\n",
       "2         0  Just like the plastic gun fear, the armour pie...\n",
       "3         0  So geology is a religion because we weren't he...\n",
       "4         0  Well done Monty. Mark that up as your first ev...\n",
       "...     ...                                                ...\n",
       "6515      1  depends on when the baby bird died.   run alon...\n",
       "6516      1  ok, sheesh, to clarify, women who arent aborti...\n",
       "6517      1  so..   eh??   hows this sound?   will it fly w...\n",
       "6518      1  I think we should put to a vote, the right of ...\n",
       "6519      1  You have a blob of tissue in your \"but(sic)\"? ...\n",
       "\n",
       "[6520 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_data=pd.read_csv(\"GEN-sarc-notsarc.csv\")\n",
    "data=main_data.copy()\n",
    "data.drop(columns=['id'],axis=1,inplace=True)\n",
    "classes = {\"notsarc\" : 0,\"sarc\" : 1}\n",
    "data[\"class\"] = data[\"class\"].map(classes)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "_38Q5FNw3BGD"
   },
   "outputs": [],
   "source": [
    "X=data['text']\n",
    "y=data['class']\n",
    "X=np.array(X)\n",
    "y=np.asarray(y).astype('int32')#.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "lpmfwitx3BGE"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data len:5216\n",
      "Class distribution\n",
      "1    2616\n",
      "0    2600\n",
      "dtype: int64\n",
      "Test data len:1304\n",
      "Class distribution\n",
      "0    660\n",
      "1    644\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Train data len:'+str(len(X_train)))\n",
    "print('Class distribution\\n'+str((pd.Series(y_train)).value_counts()))\n",
    "print('Test data len:'+str(len(X_test)))\n",
    "print('Class distribution\\n'+str((pd.Series(y_test)).value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data len:4172\n",
      "Class distribution\n",
      "0    2087\n",
      "1    2085\n",
      "dtype: int64\n",
      "Valid data len:1044\n",
      "Class distribution\n",
      "1    531\n",
      "0    513\n",
      "dtype: int64\n",
      "Test data len:1304\n",
      "Class distribution\n",
      "0    660\n",
      "1    644\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Train data len:'+str(len(X_train)))\n",
    "print('Class distribution\\n'+str((pd.Series(y_train)).value_counts()))\n",
    "print('Valid data len:'+str(len(X_valid)))\n",
    "print('Class distribution\\n'+str((pd.Series(y_valid)).value_counts()))\n",
    "print('Test data len:'+str(len(X_test)))\n",
    "print('Class distribution\\n'+str((pd.Series(y_test)).value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gradient": {},
    "id": "EDvx7R7V3BGE"
   },
   "outputs": [],
   "source": [
    "tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1'\n",
    "tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gradient": {},
    "id": "oasTqHRC3BGF"
   },
   "outputs": [],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "gradient": {},
    "id": "RfPdRUSm3BGH"
   },
   "outputs": [],
   "source": [
    "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "gradient": {},
    "id": "-YnPoQA33BGJ"
   },
   "outputs": [],
   "source": [
    "def build_classifier_model():\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    net = outputs['pooled_output']\n",
    "    net = tf.keras.layers.Dropout(0.1)(net)\n",
    "    net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n",
    "    return tf.keras.Model(text_input, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "gradient": {},
    "id": "gzCcgBG03BGJ"
   },
   "outputs": [],
   "source": [
    "classifier_model = build_classifier_model()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {},
    "id": "AwLW1NTN3BGK",
    "outputId": "28bc9c6e-21d2-485c-fc37-83ef6a509676"
   },
   "source": [
    "bert_raw_result = classifier_model(tf.constant(text_test))\n",
    "print(tf.sigmoid(bert_raw_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "gradient": {},
    "id": "jIBBkiV23BGL"
   },
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "metrics = tf.metrics.BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "gradient": {},
    "id": "Ys_RlKzz3BGL"
   },
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(32)\n",
    "valid_ds = tf.data.Dataset.from_tensor_slices((X_valid, y_valid)).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "IlKkCSm23BGM",
    "outputId": "184ce181-c7c8-4ab5-8b2a-da4b767fe96d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None,), (None,)), types: (tf.string, tf.int32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "ckUlBFJp3BGM"
   },
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "init_lr = 3e-5\n",
    "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                          num_train_steps=num_train_steps,\n",
    "                                          num_warmup_steps=num_warmup_steps,\n",
    "                                          optimizer_type='adamw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "qmrckhQb3BGM"
   },
   "outputs": [],
   "source": [
    "classifier_model.compile(optimizer=optimizer,\n",
    "                         loss=loss,\n",
    "                         metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "n3qKobso3BGM",
    "outputId": "3c1f0c8e-168c-451d-a468-ee8cc605f26a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1\n",
      "Epoch 1/3\n",
      " 84/131 [==================>...........] - ETA: 22:14 - loss: 0.5752 - binary_accuracy: 0.6778"
     ]
    }
   ],
   "source": [
    "print(f'Training model with {tfhub_handle_encoder}')\n",
    "history = classifier_model.fit(x=train_ds,\n",
    "                               validation_data=valid_ds,\n",
    "                               epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=classifier_model.predict(X_test)\n",
    "labels = [0, 1]\n",
    "print(classification_report(y_test,tf.round(tf.nn.sigmoid(y_pred)),labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "gradient": {
     "editing": false
    },
    "id": "BYeZrbCt3BGN",
    "outputId": "7d3cac5a-5d00-43a9-9039-ce55abe26da9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss, accuracy = classifier_model.evaluate(test_ds)\n",
    "\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [],
   "source": [
    "model_name='BERT_TalkingHeads_Sarcasm_GEN_'+str(accuracy)\n",
    "classifier_model.save(model_name, include_optimizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "T6u4oCva3BGN"
   },
   "outputs": [],
   "source": [
    "test_data=pd.read_csv(\"HYP-sarc-notsarc.csv\")\n",
    "test_data.drop(columns=['id'],axis=1,inplace=True)\n",
    "classes = {\"notsarc\" : 0,\"sarc\" : 1}\n",
    "test_data[\"class\"] = test_data[\"class\"].map(classes)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "cRJxs3BM3BGO"
   },
   "outputs": [],
   "source": [
    "test_X=test_data['text']\n",
    "test_y=test_data['class']\n",
    "test_X=np.array(test_X)\n",
    "test_y=np.asarray(test_y).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "1_9h-opy3BGO"
   },
   "outputs": [],
   "source": [
    "test_tf = tf.data.Dataset.from_tensor_slices((test_X, test_y)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y=classifier_model.predict(test_X)\n",
    "print(classification_report(test_y,tf.round(tf.nn.sigmoid(pred_y)),labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "xVFsVHYA3BGO",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss, accuracy = classifier_model.evaluate(test_tf)\n",
    "\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "JazexIoe3BGO"
   },
   "outputs": [],
   "source": [
    "test_data2=pd.read_csv(\"RQ-sarc-notsarc.csv\")\n",
    "test_data2.drop(columns=['id'],axis=1,inplace=True)\n",
    "classes = {\"notsarc\" : 0,\"sarc\" : 1}\n",
    "test_data2[\"class\"] = test_data2[\"class\"].map(classes)\n",
    "test_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "K3AbPnzg3BGO"
   },
   "outputs": [],
   "source": [
    "test2_X=test_data2['text']\n",
    "test2_y=test_data2['class']\n",
    "test2_X=np.array(test2_X)\n",
    "test2_y=np.asarray(test2_y).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y2=classifier_model.predict(test2_X)\n",
    "print(classification_report(test2_y,tf.round(tf.nn.sigmoid(pred_y2)),labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "2UzlDTWT3BGP",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test2_tf = tf.data.Dataset.from_tensor_slices((test2_X,test2_y)).batch(32)\n",
    "loss, accuracy = classifier_model.evaluate(test2_tf)\n",
    "\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "id": "pOFP73nb3BGP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "BERT - talking heads - Sarcasm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
